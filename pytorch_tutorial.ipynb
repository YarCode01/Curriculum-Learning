{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2,dtype=int)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6838, 0.1484],\n",
       "         [0.3328, 0.0787]]),\n",
       " tensor([[0.9779, 0.9992],\n",
       "         [0.9861, 0.2324]]),\n",
       " tensor([[0.6992, 0.1485],\n",
       "         [0.3375, 0.3387]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "z = x/y\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0787), 0.07870721817016602)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1], x[1,1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5116, 0.7009, 0.8786, 0.2163],\n",
      "        [0.6351, 0.6476, 0.9121, 0.2947],\n",
      "        [0.0952, 0.4026, 0.3520, 0.8690],\n",
      "        [0.3217, 0.8022, 0.5578, 0.5156]])\n",
      "tensor([0.5116, 0.7009, 0.8786, 0.2163, 0.6351, 0.6476, 0.9121, 0.2947, 0.0952,\n",
      "        0.4026, 0.3520, 0.8690, 0.3217, 0.8022, 0.5578, 0.5156])\n",
      "tensor([[0.5116, 0.7009, 0.8786, 0.2163, 0.6351, 0.6476, 0.9121, 0.2947],\n",
      "        [0.0952, 0.4026, 0.3520, 0.8690, 0.3217, 0.8022, 0.5578, 0.5156]])\n",
      "tensor([[0.5116, 0.7009, 0.8786, 0.2163, 0.6351, 0.6476, 0.9121, 0.2947],\n",
      "        [0.0952, 0.4026, 0.3520, 0.8690, 0.3217, 0.8022, 0.5578, 0.5156]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "print(x.view(16))\n",
    "print(x.view(-1,8))\n",
    "print(x.view(2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7862, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4404, 1.5244, 4.9361])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y*y*2\n",
    "z = z.mean()\n",
    "print(z)\n",
    "z.backward()\n",
    "x.grad ### that's how you access gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5235, 1.3156, 0.2277], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "#x.requires_grad_(False)\n",
    "#x.detach()\n",
    "#with torch.no_grad():\n",
    "\n",
    "y = x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5235, 1.3156, 0.2277]) tensor([2.5235, 3.3156, 2.2277], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = x + 2\n",
    "print(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "### forward pass\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2 \n",
    "\n",
    "print(loss)\n",
    "\n",
    "### backward\n",
    "loss.backward()\n",
    "print(w.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipe line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0000, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=0.01) \n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(forward(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.0000], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32) \n",
    "n_samples, n_features = X.shape\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "model = nn.Linear(n_features, n_features)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "for epoch in range(10000):\n",
    "\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(model(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.0000], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32) \n",
    "n_samples, n_features = X.shape\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "##model = nn.Linear(n_features, n_features)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(n_features, n_features)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "for epoch in range(10000):\n",
    "\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(model(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet\n",
    "complete list of built-in transforms: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "On Images\n",
    "---------\n",
    "CenterCrop, Grayscale, Pad, RandomAffine\n",
    "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
    "Resize, Scale\n",
    "On Tensors\n",
    "----------\n",
    "LinearTransformation, Normalize, RandomErasing\n",
    "Conversion\n",
    "----------\n",
    "ToPILImage: from tensor or ndrarray\n",
    "ToTensor : from numpy.ndarray or PILImage\n",
    "Generic\n",
    "-------\n",
    "Use Lambda \n",
    "Custom\n",
    "------\n",
    "Write own class\n",
    "Compose multiple Transforms\n",
    "---------------------------\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Custom Transforms\n",
    "# implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='./data', transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 \n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1,28*28)\n",
    "\n",
    "        output = model(images)\n",
    "        print(output.shape)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0000, -5.0000,  0.2000,  1.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,-5,0.2,3])\n",
    "torch.min(torch.ones(a.size()), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
